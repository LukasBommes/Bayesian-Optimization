{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_baesian_optimization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvz0emj1Bhox",
        "colab_type": "text"
      },
      "source": [
        "# CNN Hyperparameter Tuning with Bayesian Optimization for MNIST Classification\n",
        "\n",
        "This example demonstrate the usage of Bayesian optimization (BO) as implemented in scikit-optimize for tuning the hyper parameters of a neural network. As compared to grid search or random search less hyper parameter combinations need to be evaluated to determine the near-optimal configuration.\n",
        "\n",
        "In each iteration of BO the neural network is trained with a different set of hyper parameters and its validation accuracy is computed. A gaussian process is fitted to the validation accuracy over the space of hyper parameters. An acquistion function which is a function of the fitted gaussian process is sampled for the next suitable hyper parameter combination which is expected to increase validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlDPu2tMKe4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8NVa79X_8_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import uuid\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IncJshjtANMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQY8VjbjAR-5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows, img_cols = 28, 28\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N4ha9aRAiZp",
        "colab_type": "code",
        "outputId": "a56ccfba-a9fe-4c93-f9ed-46abc22ede79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1Ab-LTVA8XA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2-ci7qEAknU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY8kp0VbAmEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(activation, learning_rate, adam_decay, dropout, dense_units, \n",
        "                 conv_0_channels, conv_1_channels):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Conv2D(conv_0_channels, kernel_size=(3, 3),\n",
        "                  activation=activation,\n",
        "                  input_shape=input_shape))\n",
        "  model.add(tf.keras.layers.Conv2D(conv_1_channels, (3, 3), activation=activation))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(tf.keras.layers.Dropout(dropout))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(dense_units, activation=activation))\n",
        "  model.add(tf.keras.layers.Dropout(dropout))\n",
        "  model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(lr=learning_rate, decay=adam_decay),\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHVZZvAHI_IR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model(activation=\"relu\", learning_rate=0.01, adam_decay=0.0, dropout=0.25, dense_units=128, \n",
        "                 conv_0_channels=32, conv_1_channels=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruatY_J8AwZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=12,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbv4KS6RGYIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a6102f18-3474-4fa3-fe61-cc6d3584d244"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 1.2761435508728027\n",
            "Test accuracy: 0.6093999743461609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bINdNLTGI_E",
        "colab_type": "text"
      },
      "source": [
        "### Baysian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BW_ubySluUzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mount Google Drive first and enter a path where models are stored\n",
        "root_path = \"drive/My Drive/Colab Notebooks/models\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrqAB0B7JxSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9b4cc2e3-84b2-4cb2-b809-37421279bd96"
      },
      "source": [
        "!pip install scikit-optimize"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.6/dist-packages (0.7.4)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.18.4)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (20.4.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.15.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH8Mi28ZJooj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skopt import gp_minimize, gbrt_minimize\n",
        "from skopt.utils import use_named_args, dump\n",
        "from skopt.space import Real, Categorical, Integer "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eaUY0VLGwGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # define the hyper parameter search space\n",
        "# dim_activation = Categorical([\"relu\", \"tanh\", \"selu\", \"elu\", \"exponential\"], name=\"activation\")\n",
        "# dim_learning_rate = Real(1e-5, 1e-1, prior=\"log-uniform\", name=\"learning_rate\")\n",
        "# dim_adam_decay = Real(1e-8, 1e-1, prior=\"log-uniform\", name=\"adam_decay\")\n",
        "# dim_dropout = Real(0.0, 1.0, name=\"dropout\")\n",
        "# dim_dense_units = Integer(32, 512, prior=\"log-uniform\", base=2, name=\"dense_units\")\n",
        "# dim_conv_0_channels = Integer(8, 64, prior=\"log-uniform\", base=2, name=\"conv_0_channels\")\n",
        "# dim_conv_1_channels = Integer(8, 128, prior=\"log-uniform\", base=2, name=\"conv_1_channels\")\n",
        "# dim_batch_size = Integer(1, 256, prior=\"log-uniform\", base=2, name=\"batch_size\")\n",
        "\n",
        "# dimensions  = [dim_activation,\n",
        "#                dim_learning_rate,\n",
        "#                dim_adam_decay,\n",
        "#                dim_dropout,\n",
        "#                dim_dense_units,\n",
        "#                dim_conv_0_channels,\n",
        "#                dim_conv_1_channels,\n",
        "#                dim_batch_size]\n",
        "\n",
        "# #default_parameters = [\"relu\", 0.01, 0.0, 0.25, 128, 32, 64, 128]  # this yields already quite a good validation accuracy\n",
        "# default_parameters = [\"tanh\", 0.01, 1e-8, 0.0, 64, 16, 32, 128]  # start with a worse configuration to demonstrate BO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4QYRL_KECSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the hyper parameter search space\n",
        "dim_activation = Categorical([\"relu\", \"tanh\", \"selu\", \"elu\", \"exponential\"], name=\"activation\")\n",
        "dim_learning_rate = Real(1e-5, 1e-1, prior=\"log-uniform\", name=\"learning_rate\")\n",
        "dim_adam_decay = Real(1e-8, 1e-1, prior=\"log-uniform\", name=\"adam_decay\")\n",
        "dim_dropout = Real(0.0, 1.0, name=\"dropout\")\n",
        "dim_dense_units = Integer(5, 9, prior=\"uniform\", name=\"dense_units\")  # log2\n",
        "dim_conv_0_channels = Integer(3, 6, prior=\"uniform\", name=\"conv_0_channels\")  # log2\n",
        "dim_conv_1_channels = Integer(3, 7, prior=\"uniform\", name=\"conv_1_channels\")  # log2\n",
        "dim_batch_size = Integer(6, 9, prior=\"uniform\", name=\"batch_size\")  # log2\n",
        "\n",
        "dimensions  = [dim_activation,\n",
        "               dim_learning_rate,\n",
        "               dim_adam_decay,\n",
        "               dim_dropout,\n",
        "               dim_dense_units,\n",
        "               dim_conv_0_channels,\n",
        "               dim_conv_1_channels,\n",
        "               dim_batch_size]\n",
        "\n",
        "#default_parameters = [\"relu\", 0.01, 0.0, 0.25, np.log2(128), np.log2(32), np.log2(64), np.log2(128)]  # this yields already quite a good validation accuracy\n",
        "default_parameters = [\"tanh\", 0.01, 1e-8, 0.0, np.log2(64), np.log2(16), np.log2(32), np.log2(128)]  # start with a worse configuration to demonstrate BO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzyneAmxDxg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # draw a sample from the parameter space for debugging\n",
        "# from skopt.space.space import Space\n",
        "# space = Space(dimensions)\n",
        "# space.rvs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oZTM--9LbVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit model with default parameters\n",
        "#model = create_model(*default_parameters[:-1])\n",
        "#hist = model.fit(x_train, y_train, epochs=8, batch_size=128, validation_data=(x_test, y_test), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXYMshoiGGRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# objective function which trains and evaluates the model with a given hyperparameter config \n",
        "model_ids = []\n",
        "\n",
        "@use_named_args(dimensions=dimensions)\n",
        "def objective(activation, learning_rate, adam_decay, dropout, dense_units, \n",
        "              conv_0_channels, conv_1_channels, batch_size):\n",
        "  \n",
        "  print(activation, learning_rate, adam_decay, dropout, int(2**dense_units), \n",
        "                 int(2**conv_0_channels), int(2**conv_1_channels), int(2**batch_size))\n",
        "\n",
        "  model = create_model(activation, learning_rate, adam_decay, dropout, int(2**dense_units), \n",
        "                 int(2**conv_0_channels), int(2**conv_1_channels))\n",
        "  \n",
        "  model_fitted = model.fit(x_train, y_train, epochs=8, batch_size=int(2**batch_size), validation_data=(x_test, y_test), verbose=1)\n",
        "\n",
        "  accuracy = model_fitted.history[\"val_accuracy\"][-1]\n",
        "\n",
        "  id = uuid.uuid4()\n",
        "  model_ids.append(id)\n",
        "  print(\"Model {}-- Accuracy: {:.2%}\".format(id, accuracy))\n",
        "\n",
        "  # save weights\n",
        "  model.save_weights(os.path.join(root_path, 'model-{}'.format(id)) )\n",
        "\n",
        "  del model\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  return -accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpF4fozuKynd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41316ba0-e5a7-4c45-f986-d3a42613eeef"
      },
      "source": [
        "gp_result = gp_minimize(func=objective,\n",
        "                        dimensions=dimensions,\n",
        "                        n_calls=12,\n",
        "                        noise=0.01,\n",
        "                        n_jobs=-1,\n",
        "                        kappa=5,\n",
        "                        x0=default_parameters,\n",
        "                        random_state=0,\n",
        "                        verbose=True)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration No: 1 started. Evaluating function at provided point.\n",
            "tanh 0.01 1e-08 0.0 64 16 32 128\n",
            "Epoch 1/8\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.2177 - accuracy: 0.9339 - val_loss: 0.1588 - val_accuracy: 0.9480\n",
            "Epoch 2/8\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.1863 - accuracy: 0.9426 - val_loss: 0.2503 - val_accuracy: 0.9192\n",
            "Epoch 3/8\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2352 - accuracy: 0.9267 - val_loss: 0.2233 - val_accuracy: 0.9296\n",
            "Epoch 4/8\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2214 - accuracy: 0.9325 - val_loss: 0.2351 - val_accuracy: 0.9251\n",
            "Epoch 5/8\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2389 - accuracy: 0.9250 - val_loss: 0.1622 - val_accuracy: 0.9494\n",
            "Epoch 6/8\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2032 - accuracy: 0.9373 - val_loss: 0.2366 - val_accuracy: 0.9260\n",
            "Epoch 7/8\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2057 - accuracy: 0.9380 - val_loss: 0.2047 - val_accuracy: 0.9366\n",
            "Epoch 8/8\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.2612 - accuracy: 0.9192 - val_loss: 0.2455 - val_accuracy: 0.9220\n",
            "Model 7c2f32b9-6c76-491b-8fab-12e4b9467e4e-- Accuracy: 92.20%\n",
            "Iteration No: 1 ended. Evaluation done at provided point.\n",
            "Time taken: 35.5667\n",
            "Function value obtained: -0.9220\n",
            "Current minimum: -0.9220\n",
            "Iteration No: 2 started. Evaluating function at random point.\n",
            "selu 0.023826650493636678 0.010130230408794514 0.8472517387841256 128 16 16 64\n",
            "Epoch 1/8\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 1.2272 - accuracy: 0.6271 - val_loss: 0.3286 - val_accuracy: 0.9159\n",
            "Epoch 2/8\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.7143 - accuracy: 0.7691 - val_loss: 0.2628 - val_accuracy: 0.9274\n",
            "Epoch 3/8\n",
            "938/938 [==============================] - 7s 8ms/step - loss: 0.6103 - accuracy: 0.8090 - val_loss: 0.2448 - val_accuracy: 0.9301\n",
            "Epoch 4/8\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.5462 - accuracy: 0.8304 - val_loss: 0.1932 - val_accuracy: 0.9439\n",
            "Epoch 5/8\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.4984 - accuracy: 0.8461 - val_loss: 0.1730 - val_accuracy: 0.9486\n",
            "Epoch 6/8\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.4574 - accuracy: 0.8586 - val_loss: 0.1649 - val_accuracy: 0.9512\n",
            "Epoch 7/8\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.4303 - accuracy: 0.8681 - val_loss: 0.1470 - val_accuracy: 0.9564\n",
            "Epoch 8/8\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.4135 - accuracy: 0.8733 - val_loss: 0.1378 - val_accuracy: 0.9583\n",
            "Model d3628f83-003f-4095-a368-b45f7b71cd7f-- Accuracy: 95.83%\n",
            "Iteration No: 2 ended. Evaluation done at random point.\n",
            "Time taken: 56.1663\n",
            "Function value obtained: -0.9583\n",
            "Current minimum: -0.9583\n",
            "Iteration No: 3 started. Evaluating function at random point.\n",
            "tanh 0.0008140675984583295 0.004843743102654484 0.47997717237505744 128 64 16 256\n",
            "Epoch 1/8\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.4488 - accuracy: 0.8634 - val_loss: 0.1791 - val_accuracy: 0.9487\n",
            "Epoch 2/8\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.2286 - accuracy: 0.9309 - val_loss: 0.1253 - val_accuracy: 0.9629\n",
            "Epoch 3/8\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.1835 - accuracy: 0.9447 - val_loss: 0.1015 - val_accuracy: 0.9689\n",
            "Epoch 4/8\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.1624 - accuracy: 0.9509 - val_loss: 0.0896 - val_accuracy: 0.9724\n",
            "Epoch 5/8\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.1493 - accuracy: 0.9539 - val_loss: 0.0811 - val_accuracy: 0.9748\n",
            "Epoch 6/8\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.1387 - accuracy: 0.9572 - val_loss: 0.0755 - val_accuracy: 0.9770\n",
            "Epoch 7/8\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.1315 - accuracy: 0.9596 - val_loss: 0.0717 - val_accuracy: 0.9780\n",
            "Epoch 8/8\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.1265 - accuracy: 0.9612 - val_loss: 0.0673 - val_accuracy: 0.9790\n",
            "Model ad49a657-9a2a-4516-8882-34a18e885a26-- Accuracy: 97.90%\n",
            "Iteration No: 3 ended. Evaluation done at random point.\n",
            "Time taken: 36.7495\n",
            "Function value obtained: -0.9790\n",
            "Current minimum: -0.9790\n",
            "Iteration No: 4 started. Evaluating function at random point.\n",
            "tanh 0.06739390723749777 9.604073230958371e-08 0.8700872583584366 128 32 32 256\n",
            "Epoch 1/8\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 3.5890 - accuracy: 0.0997 - val_loss: 2.4023 - val_accuracy: 0.0974\n",
            "Epoch 2/8\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 3.3990 - accuracy: 0.1037 - val_loss: 2.4206 - val_accuracy: 0.1028\n",
            "Epoch 3/8\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 3.4186 - accuracy: 0.0996 - val_loss: 2.4633 - val_accuracy: 0.0980\n",
            "Epoch 4/8\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 3.5068 - accuracy: 0.1012 - val_loss: 2.6264 - val_accuracy: 0.0892\n",
            "Epoch 5/8\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 3.3867 - accuracy: 0.1006 - val_loss: 2.4975 - val_accuracy: 0.1009\n",
            "Epoch 6/8\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 3.4413 - accuracy: 0.1006 - val_loss: 2.4876 - val_accuracy: 0.1135\n",
            "Epoch 7/8\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 3.4022 - accuracy: 0.1013 - val_loss: 2.5059 - val_accuracy: 0.0980\n",
            "Epoch 8/8\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 3.4593 - accuracy: 0.1015 - val_loss: 2.4960 - val_accuracy: 0.1032\n",
            "Model 7e11e952-629e-49b6-ab14-966c732119a6-- Accuracy: 10.32%\n",
            "Iteration No: 4 ended. Evaluation done at random point.\n",
            "Time taken: 34.7707\n",
            "Function value obtained: -0.1032\n",
            "Current minimum: -0.9790\n",
            "Iteration No: 5 started. Evaluating function at random point.\n",
            "elu 0.0021285270235317324 5.775806114202406e-05 0.7586156243223574 32 16 16 256\n",
            "Epoch 1/8\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.0426 - accuracy: 0.6519 - val_loss: 0.2474 - val_accuracy: 0.9402\n",
            "Epoch 2/8\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.7010 - accuracy: 0.7710 - val_loss: 0.1724 - val_accuracy: 0.9547\n",
            "Epoch 3/8\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.6127 - accuracy: 0.8015 - val_loss: 0.1418 - val_accuracy: 0.9610\n",
            "Epoch 4/8\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.5802 - accuracy: 0.8116 - val_loss: 0.1280 - val_accuracy: 0.9637\n",
            "Epoch 5/8\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.5436 - accuracy: 0.8241 - val_loss: 0.1203 - val_accuracy: 0.9663\n",
            "Epoch 6/8\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.5188 - accuracy: 0.8342 - val_loss: 0.1081 - val_accuracy: 0.9681\n",
            "Epoch 7/8\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.4987 - accuracy: 0.8375 - val_loss: 0.1075 - val_accuracy: 0.9688\n",
            "Epoch 8/8\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 0.4884 - accuracy: 0.8408 - val_loss: 0.0957 - val_accuracy: 0.9708\n",
            "Model d9927858-84c5-4758-b254-c6604cb5b1fa-- Accuracy: 97.08%\n",
            "Iteration No: 5 ended. Evaluation done at random point.\n",
            "Time taken: 22.5187\n",
            "Function value obtained: -0.9708\n",
            "Current minimum: -0.9790\n",
            "Iteration No: 6 started. Evaluating function at random point.\n",
            "tanh 3.474343017884354e-05 1.8577490784921693e-06 0.1496748671836832 64 16 128 128\n",
            "Epoch 1/8\n",
            "469/469 [==============================] - 9s 19ms/step - loss: 0.7633 - accuracy: 0.8282 - val_loss: 0.3565 - val_accuracy: 0.9108\n",
            "Epoch 2/8\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.3281 - accuracy: 0.9117 - val_loss: 0.2609 - val_accuracy: 0.9299\n",
            "Epoch 3/8\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.2574 - accuracy: 0.9294 - val_loss: 0.2105 - val_accuracy: 0.9417\n",
            "Epoch 4/8\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.2117 - accuracy: 0.9427 - val_loss: 0.1769 - val_accuracy: 0.9520\n",
            "Epoch 5/8\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1790 - accuracy: 0.9513 - val_loss: 0.1509 - val_accuracy: 0.9596\n",
            "Epoch 6/8\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1542 - accuracy: 0.9594 - val_loss: 0.1302 - val_accuracy: 0.9645\n",
            "Epoch 7/8\n",
            "469/469 [==============================] - 9s 18ms/step - loss: 0.1330 - accuracy: 0.9659 - val_loss: 0.1148 - val_accuracy: 0.9690\n",
            "Epoch 8/8\n",
            "469/469 [==============================] - 8s 18ms/step - loss: 0.1174 - accuracy: 0.9695 - val_loss: 0.1020 - val_accuracy: 0.9734\n",
            "Model 31c76659-0282-4a1f-b482-3f86fbf835a0-- Accuracy: 97.34%\n",
            "Iteration No: 6 ended. Evaluation done at random point.\n",
            "Time taken: 69.1011\n",
            "Function value obtained: -0.9734\n",
            "Current minimum: -0.9790\n",
            "Iteration No: 7 started. Evaluating function at random point.\n",
            "elu 0.04068125410377036 4.9540735787386844e-08 0.969809067746749 256 16 16 256\n",
            "Epoch 1/8\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 6.3855 - accuracy: 0.1002 - val_loss: 2.4248 - val_accuracy: 0.1028\n",
            "Epoch 2/8\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 32.4628 - accuracy: 0.0996 - val_loss: 2.4346 - val_accuracy: 0.1009\n",
            "Epoch 3/8\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 6.2003 - accuracy: 0.1025 - val_loss: 2.4212 - val_accuracy: 0.1009\n",
            "Epoch 4/8\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 5.6451 - accuracy: 0.1006 - val_loss: 2.4805 - val_accuracy: 0.0958\n",
            "Epoch 5/8\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 6.1741 - accuracy: 0.1008 - val_loss: 2.8260 - val_accuracy: 0.1135\n",
            "Epoch 6/8\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 6.7224 - accuracy: 0.1011 - val_loss: 2.6155 - val_accuracy: 0.0892\n",
            "Epoch 7/8\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 7.4586 - accuracy: 0.0998 - val_loss: 2.7276 - val_accuracy: 0.1135\n",
            "Epoch 8/8\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 6.0884 - accuracy: 0.1024 - val_loss: 2.5236 - val_accuracy: 0.0980\n",
            "Model ca3a44d7-35be-45f4-aec3-fa399cf41404-- Accuracy: 9.80%\n",
            "Iteration No: 7 ended. Evaluation done at random point.\n",
            "Time taken: 23.4455\n",
            "Function value obtained: -0.0980\n",
            "Current minimum: -0.9790\n",
            "Iteration No: 8 started. Evaluating function at random point.\n",
            "elu 0.00019961304333831489 1.8577102840720935e-08 0.6342740579573352 512 32 64 512\n",
            "Epoch 1/8\n",
            "118/118 [==============================] - 6s 51ms/step - loss: 0.5454 - accuracy: 0.8377 - val_loss: 0.2404 - val_accuracy: 0.9321\n",
            "Epoch 2/8\n",
            "118/118 [==============================] - 6s 49ms/step - loss: 0.2527 - accuracy: 0.9254 - val_loss: 0.1544 - val_accuracy: 0.9553\n",
            "Epoch 3/8\n",
            "118/118 [==============================] - 6s 49ms/step - loss: 0.1822 - accuracy: 0.9466 - val_loss: 0.1134 - val_accuracy: 0.9656\n",
            "Epoch 4/8\n",
            "118/118 [==============================] - 6s 49ms/step - loss: 0.1467 - accuracy: 0.9560 - val_loss: 0.0882 - val_accuracy: 0.9728\n",
            "Epoch 5/8\n",
            "118/118 [==============================] - 6s 49ms/step - loss: 0.1256 - accuracy: 0.9624 - val_loss: 0.0733 - val_accuracy: 0.9768\n",
            "Epoch 6/8\n",
            "118/118 [==============================] - 6s 49ms/step - loss: 0.1113 - accuracy: 0.9666 - val_loss: 0.0671 - val_accuracy: 0.9778\n",
            "Epoch 7/8\n",
            "118/118 [==============================] - 6s 49ms/step - loss: 0.1036 - accuracy: 0.9682 - val_loss: 0.0613 - val_accuracy: 0.9800\n",
            "Epoch 8/8\n",
            "118/118 [==============================] - 6s 49ms/step - loss: 0.0940 - accuracy: 0.9716 - val_loss: 0.0551 - val_accuracy: 0.9816\n",
            "Model 4b10919d-24c5-4be8-8aa2-ba2a0b3c64db-- Accuracy: 98.16%\n",
            "Iteration No: 8 ended. Evaluation done at random point.\n",
            "Time taken: 47.8438\n",
            "Function value obtained: -0.9816\n",
            "Current minimum: -0.9816\n",
            "Iteration No: 9 started. Evaluating function at random point.\n",
            "selu 0.00045443769977252776 2.1032094091909653e-05 0.6235101011318683 64 32 16 256\n",
            "Epoch 1/8\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.7642 - accuracy: 0.7527 - val_loss: 0.2474 - val_accuracy: 0.9270\n",
            "Epoch 2/8\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.4257 - accuracy: 0.8699 - val_loss: 0.1832 - val_accuracy: 0.9460\n",
            "Epoch 3/8\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.3475 - accuracy: 0.8953 - val_loss: 0.1446 - val_accuracy: 0.9561\n",
            "Epoch 4/8\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2952 - accuracy: 0.9122 - val_loss: 0.1341 - val_accuracy: 0.9610\n",
            "Epoch 5/8\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2593 - accuracy: 0.9224 - val_loss: 0.1035 - val_accuracy: 0.9684\n",
            "Epoch 6/8\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2360 - accuracy: 0.9289 - val_loss: 0.0915 - val_accuracy: 0.9727\n",
            "Epoch 7/8\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.2120 - accuracy: 0.9372 - val_loss: 0.0817 - val_accuracy: 0.9751\n",
            "Epoch 8/8\n",
            "235/235 [==============================] - 3s 14ms/step - loss: 0.1965 - accuracy: 0.9415 - val_loss: 0.0752 - val_accuracy: 0.9758\n",
            "Model f3cb853e-0179-4109-be0d-cf0a3ca0f698-- Accuracy: 97.58%\n",
            "Iteration No: 9 ended. Evaluation done at random point.\n",
            "Time taken: 27.2975\n",
            "Function value obtained: -0.9758\n",
            "Current minimum: -0.9816\n",
            "Iteration No: 10 started. Evaluating function at random point.\n",
            "exponential 0.004467941393600852 1.2445187648498989e-08 0.6228460955466696 256 64 128 256\n",
            "Epoch 1/8\n",
            "235/235 [==============================] - 12s 50ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 2/8\n",
            "235/235 [==============================] - 12s 49ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 3/8\n",
            "235/235 [==============================] - 11s 49ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 4/8\n",
            "235/235 [==============================] - 12s 49ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 5/8\n",
            "235/235 [==============================] - 11s 49ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 6/8\n",
            "235/235 [==============================] - 12s 49ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 7/8\n",
            "235/235 [==============================] - 12s 49ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Epoch 8/8\n",
            "235/235 [==============================] - 11s 49ms/step - loss: nan - accuracy: 0.0987 - val_loss: nan - val_accuracy: 0.0980\n",
            "Model e1a2c2b2-6e81-4f40-a3dc-3ad7dd024bd7-- Accuracy: 9.80%\n",
            "Iteration No: 10 ended. Evaluation done at random point.\n",
            "Time taken: 93.8749\n",
            "Function value obtained: -0.0980\n",
            "Current minimum: -0.9816\n",
            "Iteration No: 11 started. Evaluating function at random point.\n",
            "relu 0.0006377300155643865 1.3801098575179591e-08 0.4417109212488455 512 16 32 256\n",
            "Epoch 1/8\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.3029 - accuracy: 0.9097 - val_loss: 0.0756 - val_accuracy: 0.9762\n",
            "Epoch 2/8\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0876 - accuracy: 0.9735 - val_loss: 0.0494 - val_accuracy: 0.9836\n",
            "Epoch 3/8\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0636 - accuracy: 0.9801 - val_loss: 0.0359 - val_accuracy: 0.9875\n",
            "Epoch 4/8\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0500 - accuracy: 0.9842 - val_loss: 0.0338 - val_accuracy: 0.9887\n",
            "Epoch 5/8\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0426 - accuracy: 0.9870 - val_loss: 0.0289 - val_accuracy: 0.9905\n",
            "Epoch 6/8\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0375 - accuracy: 0.9880 - val_loss: 0.0284 - val_accuracy: 0.9913\n",
            "Epoch 7/8\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0316 - accuracy: 0.9901 - val_loss: 0.0285 - val_accuracy: 0.9907\n",
            "Epoch 8/8\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0296 - accuracy: 0.9907 - val_loss: 0.0273 - val_accuracy: 0.9915\n",
            "Model 67315475-2487-4ba5-872f-c1e8f2a9c006-- Accuracy: 99.15%\n",
            "Iteration No: 11 ended. Evaluation done at random point.\n",
            "Time taken: 34.2307\n",
            "Function value obtained: -0.9915\n",
            "Current minimum: -0.9915\n",
            "Iteration No: 12 started. Searching for the next optimal point.\n",
            "exponential 1e-05 0.1 0.0 256 8 8 128\n",
            "Epoch 1/8\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 983.0308 - accuracy: 0.1011 - val_loss: 817.2855 - val_accuracy: 0.0992\n",
            "Epoch 2/8\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 686.5867 - accuracy: 0.1022 - val_loss: 688.7571 - val_accuracy: 0.0987\n",
            "Epoch 3/8\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 601.2890 - accuracy: 0.1023 - val_loss: 621.4156 - val_accuracy: 0.0972\n",
            "Epoch 4/8\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 550.6954 - accuracy: 0.1019 - val_loss: 576.7839 - val_accuracy: 0.0986\n",
            "Epoch 5/8\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 515.1641 - accuracy: 0.1020 - val_loss: 543.6459 - val_accuracy: 0.0986\n",
            "Epoch 6/8\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 488.1469 - accuracy: 0.1017 - val_loss: 517.6719 - val_accuracy: 0.0960\n",
            "Epoch 7/8\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 466.2148 - accuracy: 0.1014 - val_loss: 495.9496 - val_accuracy: 0.0958\n",
            "Epoch 8/8\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 447.8018 - accuracy: 0.1012 - val_loss: 477.6574 - val_accuracy: 0.0959\n",
            "Model 9fbe2b12-6197-4fc0-ad03-0c12534fd780-- Accuracy: 9.59%\n",
            "Iteration No: 12 ended. Search finished for the next optimal point.\n",
            "Time taken: 32.0346\n",
            "Function value obtained: -0.0959\n",
            "Current minimum: -0.9915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtarQUFi_Tdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dump(gp_result, os.path.join(root_path, \"BO_result.pkl\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7f2-KT6wzSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "44ebb061-4ee0-4a57-fba2-bf892b57d7f7"
      },
      "source": [
        "gp_result.x"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['relu',\n",
              " 0.0006377300155643865,\n",
              " 1.3801098575179591e-08,\n",
              " 0.4417109212488455,\n",
              " 9,\n",
              " 4,\n",
              " 5,\n",
              " 8]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSpUeqA2M_mM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "5780da92-1082-49c6-e3b3-55a24bfb28d7"
      },
      "source": [
        "from skopt.plots import plot_convergence\n",
        "plot_convergence(gp_result)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f77817680b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg-o6xkJveAh",
        "colab_type": "text"
      },
      "source": [
        "### Load best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUPWgJtevfQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b12d3a6d-3ad9-4d30-a954-cc3e2c6d70bf"
      },
      "source": [
        "#best_model_id = \"61504fa2-5f6e-4a89-9041-858be90208b7\"\n",
        "best_model_id = model_ids[gp_result.x_iters.index(gp_result.x)]\n",
        "#model_loaded = create_model(*(gp_result.x[:-1]))\n",
        "\n",
        "activation = gp_result.x[0]\n",
        "learning_rate = gp_result.x[1]\n",
        "adam_decay = gp_result.x[2]\n",
        "dropout = gp_result.x[3]\n",
        "dense_units = int(2**gp_result.x[4])\n",
        "conv_0_channels = int(2**gp_result.x[5])\n",
        "conv_1_channels = int(2**gp_result.x[6])\n",
        "model_loaded = create_model(activation, learning_rate, adam_decay, dropout,\n",
        "                            dense_units, conv_0_channels, conv_1_channels)\n",
        "\n",
        "model_loaded.load_weights(os.path.join(root_path, \"model-{}\".format(best_model_id)))\n",
        "\n",
        "score = model_loaded.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.02731534093618393\n",
            "Test accuracy: 0.9915000200271606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBrrVi5YT6Mf",
        "colab_type": "text"
      },
      "source": [
        "### Retrain the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVXkICJmT000",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_best = create_model(*(gp_result.x[:-1]))\n",
        "# model_best.fit(x_train, y_train, epochs=8, batch_size=gp_result.x[-1], validation_data=(x_test, y_test), verbose=1)\n",
        "# score = model_best.evaluate(x_test, y_test, verbose=0)\n",
        "# print('Test loss:', score[0])\n",
        "# print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}